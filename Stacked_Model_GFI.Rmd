---
title: "Stacked Model (GFI)"
author: "Hip Hip Array"
date: "12/03/2021"
output:
  html_document:
    highlight: tango
    theme: united
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Install packages and Load Data

```{r, cache=TRUE}
#install.packages("devtools")
#install.packages("nflfastR")
#install.packages("gsisdecoder")
#install.packages(gdata)

library(nflfastR)

future::plan("multisession")
pbp <- load_pbp(2010:2020, file_type = "qs")
str(pbp)

#library(gdata)
#pbp$year <- left(pbp$game_date, n=4)
```

## Set up "Going For It" (GFI) Data
```{r}
#Only pull plays that are a fourth down attempt
GFI <- pbp[!is.na(pbp$play_type), ]
GFI <- GFI[!is.na(GFI$play_id) & GFI$down == 4 & GFI$punt_attempt == 0 & GFI$field_goal_attempt == 0 & GFI$play_type != "no_play" & GFI$play_type != "qb_kneel",]
```



## Set up GFI data for all models
```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric
library(dplyr)

#Include all variables for step function, exclude NA rows
GFI_ALL <- GFI[!is.na(GFI$fourth_down_converted),]

## Randomize the rows in the data (shuffling the rows)
set.seed(123)
GFI_ALL <- slice(GFI_ALL, sample(1:n()))
```


## Variable Selection with GLM

### Training
```{r, cache=TRUE}
GFI_GLM_ALL <- select(GFI_ALL, 
  fourth_down_converted,
  season_type, 
  week, 
  posteam_type, 
  yardline_100, 
  quarter_seconds_remaining, 
  half_seconds_remaining, 
  game_seconds_remaining, 
  game_half, 
  qtr, 
  goal_to_go, 
  ydstogo, 
  play_type, 
  shotgun, 
  no_huddle, 
  home_timeouts_remaining, 
  away_timeouts_remaining, 
  timeout, 
  posteam_timeouts_remaining, 
  defteam_timeouts_remaining, 
  total_home_score, 
  total_away_score, 
  posteam_score, 
  defteam_score, 
  score_differential, 
  special_teams_play, 
  fixed_drive, 
  away_score, 
  home_score, 
  location, 
  div_game, 
  roof, 
  surface, 
  home_opening_kickoff
)
GFI_GLM_ALL <- GFI_GLM_ALL %>% mutate_if(is.character, as.factor)

GFI_GLM_ALL <- GFI_GLM_ALL %>% select(where(~n_distinct(.) > 1))

train_set <- sample(1:nrow(GFI_GLM_ALL), 0.7*nrow(GFI_GLM_ALL))

#Training set 
gfi_glm_train <- GFI_GLM_ALL[train_set,]
gfi_glm_validation <- GFI_GLM_ALL[-train_set,]

library(stats)
model_glm <- glm(fourth_down_converted ~ ., data = gfi_glm_train, family = "binomial", control=list(maxit = 100))
model_glm <- step(model_glm, direction="backward")
summary(model_glm)
```

### Predicting
```{r}
predict_glm <- predict(model_glm, newdata = gfi_glm_validation, type = "response")
predict_glm_factor <- ifelse(predict_glm < 0.5, 0, 1)
predict_glm_factor <- as.factor(predict_glm_factor)
library(caret)
confusionMatrix(predict_glm_factor, as.factor(gfi_glm_validation$fourth_down_converted))
```

Now we will run future models on just inputs the stepwise GLM found significant.

```{r}
#Include only variables we want to use in prediction
GFI_small <- select(GFI_ALL, 
  fourth_down_converted,
  yardline_100,
  half_seconds_remaining,
  game_half,
  goal_to_go,
  ydstogo,
  play_type,
  timeout,
  total_home_score,
  total_away_score,
  posteam_score,
  defteam_score,
  special_teams_play,
  away_score,
  home_score
)

GFI_small <- GFI_small %>% mutate_if(is.character, as.factor)

GFI_small <- GFI_small %>% select(where(~n_distinct(.) > 1))

library(janitor)
GFI_small <- clean_names(GFI_small)

#Model Matrix for ANN
GFI_mm <- as.data.frame(model.matrix(~.-1,GFI_small))


#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
#Create Labels for KNN 
GFI_norm <- as.data.frame(lapply(GFI_mm[-1], normalize))
GFI_labels <- GFI_mm[,1]
```

## GLM

### Training
```{r}
library(stats)
model_glm <- glm(fourth_down_converted ~ ., data = GFI_small, family = "binomial", control=list(maxit = 100))
summary(model_glm)
```

### Predicting
```{r}
predict_glm <- predict(model_glm, newdata = GFI_small, type = "response")
predict_glm_factor <- ifelse(predict_glm < 0.5, 0, 1)
predict_glm_factor <- as.factor(predict_glm_factor)
library(caret)
confusionMatrix(predict_glm_factor, as.factor(GFI_small$fourth_down_converted))
```

## ANN

### Training
```{r, cache=TRUE}
library(neuralnet)
model_ann <- neuralnet(fourth_down_converted ~ ., data = GFI_mm, stepmax=1000000, hidden=3)
plot(model_ann)
```

### Predicting
```{r}
library(neuralnet)
predict_ann <- compute(model_ann, GFI_mm)
predict_ann <- predict_ann$net.result
predict_ann_factor <- ifelse(predict_ann < 0.5, 0, 1)
predict_ann_factor <- as.factor(predict_ann_factor)

confusionMatrix(predict_ann_factor, as.factor(GFI_mm$fourth_down_converted))
```


## KNN

### Training & Predicting
```{r}
library(class)

knn_pred <- knn(train = GFI_norm, test = GFI_norm,
                      cl = GFI_labels, k=5)

confusionMatrix(as.factor(knn_pred), as.factor(GFI_labels))
```


## SVM

### Training
```{r}
library(kernlab)
model_svm <- ksvm(fourth_down_converted ~ ., data = GFI_small, kernel = "rbfdot", kpar=list(sigma=0.2))
```

### Predicting
```{r}
predict_svm <- predict(model_svm, GFI_small)
predict_svm <- ifelse(predict_svm < 0.5, 0, 1)

confusionMatrix(as.factor(predict_svm), as.factor(GFI_labels))
```

## Decision Tree

### Training
```{r}
library(C50)

model_tree <- C5.0(as.factor(fourth_down_converted) ~ ., data=GFI_small)
summary(model_tree)
```

### Predicting
```{r}
predict_tree <- predict(model_tree, GFI_small)

confusionMatrix(predict_tree, as.factor(GFI_labels))
```


## Summary Kappas
Kappa for each model is as follows:

- Logistic Regression: 0.5533
- KNN: 0.5048
- ANN: 0.6133
- SVM: 0.8472  
- Decision Tree: 0.6376 

# Stacked Model

## Data Frame of all Predictions
```{r}
predictions <- as.data.frame(GFI_labels)
predictions$glm <- predict_glm
predictions$knn <- knn_pred
predictions$ann <- predict_ann
predictions$svm <- predict_svm
predictions$tree <- predict_tree

str(predictions)
summary(predictions)
```

## Split into Train and Validation Sets

```{r}
set.seed(123)
train_set <- sample(1:nrow(predictions), 0.7*nrow(predictions))

#Training set 
train_data <- predictions[train_set,]
str(train_data)

val_data <- predictions[-train_set,]
str(val_data)
```


## Decision Tree

```{r}
library(C50)

set.seed(123)

second_level_tree <- C5.0(as.factor(GFI_labels) ~ ., data=train_data)
summary(second_level_tree)
```

## Validate Decision Tree

```{r}
predict_second_level <- predict(second_level_tree, val_data)

plot(second_level_tree)

library(caret)
confusionMatrix(predict_second_level, as.factor(val_data$GFI_labels))
```

# Decision Predictions

(Jim Harbaugh please read this part)

We will now create a function that uses the trained model to determine if a team should "Go For It" on 4th Down.


## Stacked Logistic Model
First, we want a stacked model that outputs a probability, and not a binary response. We will use a logistic stacked model instead of a decision tree. KNN will not be used because it is hard to form a lightweight function.

### Training
```{r, cache=TRUE}
stacked_glm <- glm(GFI_labels ~ .-knn, data=train_data)
summary(stacked_glm)
```

## Decision Function

Now we will define the actual decision function. The function requires as input a data frame with the following fields:

fourth_down_converted, yardline_100, half_seconds_remaining, game_half, goal_to_go, ydstogo, play_type, timeout, total_home_score, total_away_score, posteam_score, defteam_score, special_teams_play, away_score, home_score, season, home_team, posteam, roof, down, posteam_timeouts_remaining, defteam_timeouts_remaining

It requires a data frame called models that contains the following fields:

ann_model, svm_model, glm_model, tree_model, stacked_glm


```{r}

gfi <- function(df, models, oppteam){

  model_outs <- data.frame(
    "glm" = predict(models$glm_model, newdata=df),
    "ann" = compute(models$ann_model, df)$net.result,
    "svm" = predict(models$svm_model, df),
    "tree" = predict(models$tree, df)
  )

  library(neuralnet)
  prob_success <- predict(models$stacked_glm, model_outs)

  pos_df <- df
  pos_df$down <- 1
  pos_df$ydstogo <- 10
  pos_df$yardline_100 <- pos_df$yardline_100 - pos_df$ydstogo

  success <- nflfastR::calculate_expected_points(pos_df) %>%
    dplyr::select(ep)

  opp_df <- df
  opp_df$posteam <- oppteam
  opp_df$down <- 1
  opp_df$ydstogo <- 10
  opp_df$yardline_100 <- 100 - pos_df$yardline_100

  failure <- nflfastR::calculate_expected_points(opp_df) %>%
    dplyr::select(ep)

  return (ifelse((prob_success * success$ep + (1-prob_success) * failure$ep * -1) > 0, "Go For It", "Don't Go For It"))

}
```

Now that the function has been defined...

```{r}
input_1 <- data.frame(
  "fourth_down_converted" = ,
  "yardline_100" = ,
  "half_seconds_remaining" = ,
  "game_half" = ,
  "goal_to_go" = ,
  "ydstogo" = ,
  "play_type" = ,
  "timeout" = ,
  "total_home_score" = ,
  "total_away_score" = ,
  "posteam_score" = ,
  "defteam_score" = ,
  "special_teams_play" = ,
  "away_score" = ,
  "home_score" = ,
  "season" = ,
  "home_team" = ,
  "posteam" = ,
  "roof" = ,
  "down" = ,
  "posteam_timeouts_remaining" = ,
  "defteam_timeouts_remaining," =  
)
```