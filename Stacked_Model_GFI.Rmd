---
title: "Stacked Model (GFI)"
author: "Mark Cappaert"
date: "12/1/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Install packages and Load Data

```{r, cache=TRUE}
#install.packages("devtools")
#install.packages("nflfastR")
#install.packages("gsisdecoder")
#install.packages(gdata)

library(nflfastR)

future::plan("multisession")
pbp <- load_pbp(2010:2020, file_type = "qs")
str(pbp)

#library(gdata)
#pbp$year <- left(pbp$game_date, n=4)
```

## Set up "Going For It" (GFI) Data
```{r}
#Only pull plays that are a fourth down attempt
GFI <- pbp[!is.na(pbp$play_type), ]
GFI <- GFI[!is.na(GFI$play_id) & GFI$down == 4 & GFI$punt_attempt == 0 & GFI$field_goal_attempt == 0 & GFI$play_type != "no_play" & GFI$play_type != "qb_kneel",]
```



## Set up GFI data for all models
```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric
library(dplyr)

#Include all variables for step function, exclude NA rows
GFI_ALL <- GFI[!is.na(GFI$fourth_down_converted),]

## Randomize the rows in the data (shuffling the rows)
set.seed(123)
GFI_ALL <- slice(GFI_ALL, sample(1:n()))
```


## Variable Selection with GLM

### Training
```{r, cache=TRUE}
GFI_GLM_ALL <- select(GFI_ALL, 
  fourth_down_converted,
  season_type, 
  week, 
  posteam_type, 
  yardline_100, 
  quarter_seconds_remaining, 
  half_seconds_remaining, 
  game_seconds_remaining, 
  game_half, 
  qtr, 
  goal_to_go, 
  ydstogo, 
  play_type, 
  shotgun, 
  no_huddle, 
  home_timeouts_remaining, 
  away_timeouts_remaining, 
  timeout, 
  posteam_timeouts_remaining, 
  defteam_timeouts_remaining, 
  total_home_score, 
  total_away_score, 
  posteam_score, 
  defteam_score, 
  score_differential, 
  opp_safety_prob, 
  opp_td_prob, 
  safety_prob, 
  td_prob, 
  ep, 
  total_home_epa, 
  total_away_epa, 
  total_home_rush_epa, 
  total_home_pass_epa, 
  total_away_rush_epa, 
  total_away_pass_epa, 
  comp_yac_epa, 
  total_home_comp_air_epa, 
  total_away_comp_air_epa, 
  total_home_comp_yac_epa, 
  total_away_comp_yac_epa, 
  total_home_raw_air_epa, 
  total_away_raw_air_epa, 
  total_home_raw_yac_epa, 
  total_away_raw_yac_epa, 
  wp, 
  def_wp, 
  home_wp, 
  away_wp, 
  special_teams_play, 
  fixed_drive, 
  away_score, 
  home_score, 
  location, 
  div_game, 
  roof, 
  surface, 
  home_opening_kickoff
)
GFI_GLM_ALL <- GFI_GLM_ALL %>% mutate_if(is.character, as.factor)

GFI_GLM_ALL <- GFI_GLM_ALL %>% select(where(~n_distinct(.) > 1))

train_set <- sample(1:nrow(GFI_GLM_ALL), 0.7*nrow(GFI_GLM_ALL))

#Training set 
gfi_glm_train <- GFI_GLM_ALL[train_set,]
gfi_glm_validation <- GFI_GLM_ALL[-train_set,]

library(stats)
model_glm <- glm(fourth_down_converted ~ ., data = gfi_glm_train, family = "binomial", control=list(maxit = 100))
model_glm <- step(model_glm, direction="backward")
summary(model_glm)
```

### Predicting
```{r}
predict_glm <- predict(model_glm, newdata = gfi_glm_validation, type = "response")
predict_glm_factor <- ifelse(predict_glm < 0.5, 0, 1)
predict_glm_factor <- as.factor(predict_glm_factor)
library(caret)
confusionMatrix(predict_glm_factor, as.factor(gfi_glm_validation$fourth_down_converted))
```

Now we will run future models on just inputs the stepwise GLM found significant.

```{r}
#Include only variables we want to use in prediction
GFI_small <- select(GFI_ALL, 
  fourth_down_converted,
  yardline_100,
  half_seconds_remaining,
  game_half,
  goal_to_go,
  ydstogo,
  play_type,
  shotgun,
  home_timeouts_remaining,
  timeout,
  total_home_score,
  total_away_score,
  posteam_score,
  defteam_score,
  td_prob,
  total_home_epa,
  total_home_rush_epa,
  comp_yac_epa,
  wp,
  home_wp,
  special_teams_play,
  away_score,
  home_score,
  home_opening_kickoff
)

GFI_small <- GFI_small %>% mutate_if(is.character, as.factor)

GFI_small <- GFI_small %>% select(where(~n_distinct(.) > 1))

library(janitor)
GFI_small <- clean_names(GFI_small)

#Model Matrix for ANN
GFI_mm <- as.data.frame(model.matrix(~.-1,GFI_small))


#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
#Create Labels for KNN 
GFI_norm <- as.data.frame(lapply(GFI_mm[-1], normalize))
GFI_labels <- GFI_mm[,1]
```

## GLM

### Training
```{r}
library(stats)
model_glm <- glm(fourth_down_converted ~ ., data = GFI_small, family = "binomial", control=list(maxit = 100))
summary(model_glm)
```

### Testing
```{r}
predict_glm <- predict(model_glm, newdata = GFI_small, type = "response")
predict_glm_factor <- ifelse(predict_glm < 0.5, 0, 1)
predict_glm_factor <- as.factor(predict_glm_factor)
library(caret)
confusionMatrix(predict_glm_factor, as.factor(GFI_small$fourth_down_converted))
```

## ANN

### Training
```{r, cache=TRUE}
library(neuralnet)
model_ann <- neuralnet(fourth_down_converted ~ ., data = GFI_mm, stepmax=1000000, hidden=3)
plot(model_ann)
```

### Predicting
```{r}
library(neuralnet)
predict_ann <- compute(model_ann, GFI_mm)
predict_ann <- predict_ann$net.result
predict_ann_factor <- ifelse(predict_ann < 0.5, 0, 1)
predict_ann_factor <- as.factor(predict_ann_factor)

confusionMatrix(predict_ann_factor, as.factor(GFI_mm$fourth_down_converted))
```


## KNN

### Training & Predicting
```{r}
library(class)

knn_pred <- knn(train = GFI_norm, test = GFI_norm,
                      cl = GFI_labels, k=76)

confusionMatrix(as.factor(knn_pred), as.factor(GFI_labels))
```


## SVM

### Training
```{r}
library(kernlab)
model_svm <- ksvm(fourth_down_converted ~ ., data = GFI_small, kernel = "rbfdot", kpar=list(sigma=1))
```

### Predicting
```{r}
predict_svm <- predict(model_svm, GFI_small)
predict_svm <- ifelse(predict_svm < 0.5, 0, 1)

confusionMatrix(as.factor(predict_svm), as.factor(GFI_labels))
```

## Decision Tree

### Training
```{r}
library(C50)

model_tree <- C5.0(as.factor(fourth_down_converted) ~ ., data=GFI_small)
summary(model_tree)
```

### Predicting
```{r}
predict_tree <- predict(model_tree, GFI_small)

confusionMatrix(predict_tree, as.factor(GFI_labels))
```


## Summary Kappas
Kappa for each model is as follows:

- Logistic Regression: 0.5533
- KNN: 0.2667
- ANN: 0.6133
- SVM: 0.9941  
- Decision Tree: 0.6376 

# Stacked Model

## Data Frame of all Predictions
```{r}
predictions <- as.data.frame(GFI_labels)
predictions$glm <- predict_glm
predictions$knn <- knn_pred
predictions$ann <- predict_ann
predictions$svm <- predict_svm
predictions$tree <- predict_tree

str(predictions)
summary(predictions)
```

## Split into Train and Validation Sets

```{r}
set.seed(123)
train_set <- sample(1:nrow(predictions), 0.7*nrow(predictions))

#Training set 
train_data <- predictions[train_set,]
str(train_data)

val_data <- predictions[-train_set,]
str(val_data)
```


## Decision Tree

```{r}
library(C50)

set.seed(123)

second_level_tree <- C5.0(as.factor(GFI_labels) ~ ., data=train_data)
summary(second_level_tree)
```

## Validate Decision Tree

```{r}
predict_second_level <- predict(second_level_tree, val_data)

plot(second_level_tree)

library(caret)
confusionMatrix(predict_second_level, as.factor(val_data$GFI_labels))
```

# Preliminary Conclusions

## Fourth Down Conversion Success

Based on models above, we believe we are on track to achieving our objectives. All of the models are reasonably accurate and provide valuable insight with varying levels of interpretability. Our SVM model is our most accurate however it may be overfitting.
