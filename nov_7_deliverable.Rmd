---
title: "Project 2 Deliverable"
author: "Hip Hip Array"
date: "11/7/2021"
  html_document: 
    code_folding: hide
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load Data

```{r, cache=TRUE}
library(nflfastR)

future::plan("multisession")
pbp <- load_pbp(2010:2020, file_type = "qs")
str(pbp)
```

# Fourth Down Conversion Success

## Set up "Going For It" (GFI) Data
```{r}
#Only pull plays that are a fourth down attempt
GFI <- pbp[!is.na(pbp$play_type), ]
GFI <- GFI[!is.na(GFI$play_id) & GFI$down == 4 & GFI$punt_attempt == 0 & GFI$field_goal_attempt == 0 & GFI$play_type != "no_play" & GFI$play_type != "qb_kneel",]
```



## Set up GFI data for GLM, KNN, and ANN Models
```{r}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric
library(dplyr)
GFI_cond <- select(GFI, fourth_down_converted, posteam_type, yardline_100, half_seconds_remaining, game_half, ydstogo, posteam_score, defteam_score, season_type)

GFI_mm <- as.data.frame(model.matrix(~.-1,GFI_cond))

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
GFI_random <- GFI_mm[sample(nrow(GFI_mm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
GFI_norm <- as.data.frame(lapply(GFI_random, normalize))
```


## Getting Train and Test Samples

```{r}
# Selects 10000 random rows for test data
set.seed(12345)
test_set_2 <- sample(1:nrow(GFI_norm), 1057) 
test_set_3 <- sample(1:nrow(GFI_cond), 1057) 
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

# Create a train set and test set
#First the predictors - all columns except the yyes column
GFI_train_2 <- GFI_norm[-test_set_2, -match("fourth_down_converted",names(GFI_norm))]
GFI_test_2 <- GFI_norm[test_set_2, -match("fourth_down_converted",names(GFI_norm))]

#Now the response (aka Labels) 
GFI_train_labels <- GFI_norm[-test_set_2, "fourth_down_converted"]
GFI_test_labels <- GFI_norm[test_set_2, "fourth_down_converted"]

#Ann Training and Test Set
GFI_train_ANN <- GFI_norm[-test_set_2,]
GFI_test_ANN <- GFI_norm[test_set_2,]

#Logistic Training and Test Set
GFI_train_glm <- GFI_cond[-test_set_3,]
GFI_test_glm <- GFI_cond[test_set_3,]

```


## Run GLM Model
```{r}
#GLM Model using a handful of predictors
#NOTE: Want to include interaction between year and team, also want to include weather and how long the current drive has been

glm_mod1 <- glm(fourth_down_converted ~ posteam_type + yardline_100 + half_seconds_remaining + game_half + ydstogo + posteam_score + defteam_score + season_type, data = GFI_train_glm, family = binomial)


summary(glm_mod1)
```

### Create Cross Table of GLM model
```{r}
GFI_test_glm$predict_4th_down_prob <- predict(glm_mod1, newdata = GFI_test_glm, type = "response")
GFI_test_glm$predict_4th_down <- ifelse(GFI_test_glm$predict_4th_down_prob >= 0.5, 1, 0)

GFI_test_glm$predict_4th_down <- factor(GFI_test_glm$predict_4th_down, levels = c(0, 1))

# Evaluate glm model results
library(gmodels)
CrossTable(x = GFI_test_glm$fourth_down_converted, y = GFI_test_glm$predict_4th_down, 
           prop.chisq=FALSE)
```


## Neural Network
```{r, cache=TRUE}
library(neuralnet)

# simple ANN with only 1 hidden layer with 3 neurons
ANN_mod1 <- neuralnet(formula = fourth_down_converted ~ ., data = GFI_train_ANN, stepmax=1000000, hidden = 3)
plot(ANN_mod1)
```

### Neural Network model results
```{r}
library(caret)
# obtain model results
model_results <- neuralnet::compute(ANN_mod1, GFI_test_ANN[-1])
# obtain predicted fourth down values
predicted_fourth_down <- model_results$net.result
# examine the correlation between predicted and actual values
cor(predicted_fourth_down, GFI_test_ANN$fourth_down_converted)
```

### Create Cross Table of ANN Model
```{r}
library(gmodels)
prediction <- ifelse(predicted_fourth_down >= 0.5, 1, 0)
confusionMatrix(as.factor(prediction), as.factor(GFI_test_ANN$fourth_down_converted), positive='1')
CrossTable(x=GFI_test_ANN$fourth_down_converted, y=prediction, prop.chisq=FALSE)
```

## KNN Model
```{r}
library(class)
library(caret)
sqrt(nrow(GFI_train_2))

#Run KNN on train data, create predictions for test data
GFI_test_pred <- knn(train = GFI_train_2, test = GFI_test_2,
                      cl = GFI_train_labels, k=56)

#Evaluate model results
library(gmodels)
CrossTable(x = GFI_test_labels, y = GFI_test_pred, 
           prop.chisq=FALSE)
```


## Preliminary Conclusions

 Based on models above, I believe we are on track to achieving our objectives. All of the models are reasonably accurate and provide valuable insight with varying levels of interpretability. Our ANN model is our most accurate however it loses interpretability which is important in the context of this project (especially for football coaches trying to make decisions in the game). I would like to improve the models by continuing to test additional predictors such as weather, current drive length and an interaction betweeen year and team. Additionally, we would like to continue testing thresholds "K" values, and neural network steps in order to continue improving our models. Finally, I would like to attempt a decision tree analysis as this would also give coaches interpretability.
 
# Field Goal Success

## Data Cleaning
```{r}
# Consider only non-blocked field goals
field_goals <- pbp[!is.na(pbp$field_goal_attempt) & pbp$field_goal_attempt == 1,]
field_goals <- field_goals[field_goals$field_goal_result != "blocked",]

field_goals$field_goal_result <- as.factor(field_goals$field_goal_result)
field_goals$weather <- as.factor(field_goals$weather)
field_goals$season_type <- as.factor(field_goals$season_type)
field_goals$temp <- ifelse(is.na(field_goals$temp), 72, field_goals$temp)
field_goals$wind <- ifelse(is.na(field_goals$wind), 0, field_goals$wind)
```


## Run Logistic Regression Model for successful field goal attempts
```{r}
field_goal_glm1 <- glm(success ~ temp + wind  + yardline_100 + game_seconds_remaining + 
                         season_type + score_differential, data = field_goals, family = binomial)

summary(field_goal_glm1)
```



## ANN Model

### Getting Train and Test Samples
```{r}
# Normalize data
pbpmm <- as.data.frame(model.matrix(~.-1,pbp))

set.seed(12345)

pbp_random <- pbpmm[sample(nrow(pbpmm)), ]
normalize <- function(x) {
  rerturn ((x - min(x)) / (max(x) - min(x)))
}
pbp_norm <- as.data.frame(lapply(pbp_random, normalize))

# Test and traning data
test_set <- sample(1:nrow(pbp_norm), 100000) #not sure about what value would be good to use
pbp_train <- pbp_norm[-test_set, -match("field_goal_made", names(pbp_norm))]
pbp_test <- pbp_norm[test_set, -match("field_goal_made", names(pbp_norm))]

pbp_train_labels <- pbp_norm[-test_set, "field_goal_made"]
pbp_test_labels <- pbp_norm[test_set, "field_goal_made"]

pbp_train_ANN <- pbp_norm[-test_set, ] 
pbp_test_ANN <- pbp_norm[test_set, ]
```

### Creating Ann Prediction
```{r}
library(neuralnet)
pbp_model <- neuralnet(formula = pbp$field_goal_made ~ . , data = pbp_train_ANN)

model_results1 <- compute(pbp_model, pbp_test_ANN[-53])
predicted_field_goal_made <- model_results1$net.result

prediction1 <- ifelse(predicted_field_goal_made >= 0.1, 1, 0)
```


### Ann Confusion Matrix
```{r}
library(gmodels)
CrossTable(x = pbp_test_labels, y = prediction1, prop.chisq = FALSE)
```

## Run Knn Model
```{r}
library(class)
library(caret)

knum <- sqrt(nrow(pbp_train))

pbp_test_pred <- knn(train = pbp_train, test = pbp_test, cl = pbp_train_labels, k= knum)

library(gmodels)
CrossTable(x = pbp_test_labels, y= pbp_test_pred, prop.chisq=FALSE)

```

# Expected Punt Distance

## Data Cleaning
```{r}
punts <- pbp[!is.na(pbp$play_type), ]
punts$play_type <- as.factor(punts$play_type)
summary(punts$play_type)

# Simplifying assumption: Ignore all punts that end in a score, which represent less than 1% of observations
punts <- punts[punts$play_type == "punt" & punts$series_result == "Punt",]
punts$series_result <- as.factor(punts$series_result)
punts$end_spot <- ifelse(punts$touchback, 75, 100 - punts$yardline_100 + punts$kick_distance - punts$return_yards)

punts_relevant <- punts[,c("season_type", "posteam_type", "yardline_100", "week", "game_seconds_remaining", "game_half", "home_timeouts_remaining", "away_timeouts_remaining", "score_differential", "roof", "surface", "temp", "wind", "end_spot")]
punts_relevant[sapply(punts_relevant, is.character)] <- lapply(punts_relevant[sapply(punts_relevant, is.character)], 
                                       as.factor)
punts_relevant$temp <- ifelse(is.na(punts_relevant$temp), 72, punts_relevant$temp)
punts_relevant$wind <- ifelse(is.na(punts_relevant$wind), 0, punts_relevant$wind)

str(punts_relevant)
summary(punts_relevant)
```

### Linear Regression
```{r}
model1 <- lm(formula=end_spot ~ .-game_seconds_remaining -game_half -home_timeouts_remaining, data=punts_relevant)
summary(model1)
```

### TODO: Split into train/test and measure accuracy

TODO

